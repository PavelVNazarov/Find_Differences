Обучение системы для поиска отличий на изображениях требует комбинации методов компьютерного зрения и машинного обучения. Рассмотрим поэтапный подход:

1. Подготовка данных
Требования к данным:

Парные изображения (оригинал + модифицированная версия)

Разметка (маски различий или bounding boxes)

Баланс между похожими и различными изображениями

Пример структуры датасета:

Copy
dataset/
├── train/
│   ├── pair_1/
│   │   ├── original.jpg
│   │   ├── modified.jpg
│   │   └── mask.png
│   ├── pair_2/
│   │   ├── ...
├── test/
│   ├── ...
2. Выбор подхода
a) Метрическое обучение (Siamese Networks)
python
Copy
import tensorflow as tf
from tensorflow.keras import layers, Model

def create_siamese_model(input_shape):
    input_a = layers.Input(shape=input_shape)
    input_b = layers.Input(shape=input_shape)

    base_cnn = tf.keras.applications.ResNet50(
        weights='imagenet',
        include_top=False,
        input_shape=input_shape
    )

    features_a = base_cnn(input_a)
    features_b = base_cnn(input_b)

    distance = layers.Lambda(
        lambda x: tf.abs(x[0] - x[1])
    )([features_a, features_b])

    x = layers.GlobalAveragePooling2D()(distance)
    x = layers.Dense(256, activation='relu')(x)
    outputs = layers.Dense(1, activation='sigmoid')(x)

    return Model(inputs=[input_a, input_b], outputs=outputs)

model = create_siamese_model((256, 256, 3))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
b) Сегментация различий (U-Net)
python
Copy
def unet_model(input_size=(256, 256, 3)):
    inputs = layers.Input(input_size)

    # Encoder
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)

    # Decoder
    up1 = layers.UpSampling2D(size=(2, 2))(pool1)
    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(up1)

    # Output
    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv2)

    return Model(inputs=inputs, outputs=outputs)

model = unet_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['IoU'])
3. Аугментация данных
python
Copy
from albumentations import (
    Compose, HorizontalFlip, VerticalFlip, Rotate,
    RandomBrightnessContrast, GaussianBlur, OpticalDistortion
)

augmentation = Compose([
    HorizontalFlip(p=0.5),
    VerticalFlip(p=0.5),
    Rotate(limit=30, p=0.5),
    RandomBrightnessContrast(p=0.3),
    GaussianBlur(p=0.2),
    OpticalDistortion(p=0.3)
])

def augment_images(original, modified, mask):
    augmented = augmentation(
        image=original,
        mask=modified,
        mask2=mask
    )
    return augmented['image'], augmented['mask'], augmented['mask2']
4. Обучение модели
python
Copy
def create_generator(data_path, batch_size=8):
    while True:
        for batch in load_batches(data_path, batch_size):
            orig_batch = preprocess(batch['original'])
            mod_batch = preprocess(batch['modified'])
            mask_batch = preprocess(batch['mask'])

            # Аугментация
            orig_batch, mod_batch, mask_batch = augment_batch(
                orig_batch, mod_batch, mask_batch
            )

            yield [orig_batch, mod_batch], mask_batch

model.fit(
    create_generator('dataset/train'),
    validation_data=create_generator('dataset/test'),
    epochs=50,
    steps_per_epoch=1000,
    validation_steps=200
)
5. Постобработка результатов
python
Copy
def postprocess_prediction(pred_mask, threshold=0.5):
    # Бинаризация
    binary_mask = (pred_mask > threshold).astype(np.uint8)

    # Морфологические операции
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    cleaned_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)

    # Поиск контуров
    contours, _ = cv2.findContours(cleaned_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    return contours
6. Оценка модели
Метрики:

IoU (Intersection over Union)

Precision/Recall

F1-Score

Mean Average Precision (mAP)

python
Copy
def calculate_iou(true_mask, pred_mask):
    intersection = np.logical_and(true_mask, pred_mask)
    union = np.logical_or(true_mask, pred_mask)
    return np.sum(intersection) / np.sum(union)
7. Доработка и оптимизация
Transfer Learning: Использование предобученных моделей (ResNet, EfficientNet)

Attention Mechanisms: Добавление attention layers для фокусировки на важных областях

Semi-Supervised Learning: Использование неразмеченных данных

Active Learning: Интерактивное обучение с участием человека

8. Интеграция в приложение
python
Copy
class AIDifferenceDetector:
    def __init__(self, model_path):
        self.model = tf.keras.models.load_model(model_path)
        self.preprocess = tf.keras.applications.resnet50.preprocess_input

    def detect_differences(self, img1, img2):
        # Предобработка
        img1 = self.preprocess(img1)
        img2 = self.preprocess(img2)

        # Предсказание
        pred_mask = self.model.predict([np.expand_dims(img1, 0),
                                      np.expand_dims(img2, 0)])

        # Постобработка
        return postprocess_prediction(pred_mask[0])
Советы для улучшения качества:
Используйте разные типы различий в данных:

Текстовые изменения

Графические модификации

Изменения цвета и геометрии

Добавьте сложные случаи:

Частичные перекрытия

Изменения при разных условиях освещения

Разные углы съемки

Используйте adversarial examples для повышения устойчивости модели

Реализуйте multi-task learning:

Одновременное предсказание масок и классификация типа изменений

Оптимизируйте для edge-устройств:

Квантование модели

Использование MobileNet-архитектур

Оптимизация памяти

Этот подход позволяет создать систему, которая может находить как явные, так и скрытые различия, работать с разными типами изображений и адаптироваться к новым видам изменений через дообучение.
